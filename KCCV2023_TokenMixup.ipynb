{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TokenMixup (NeurIPS 2022)\n",
        "\n",
        "Hyeong Kyu Choi<sup>*</sup>, Joonmyung Choi<sup>*</sup>, Hyunwoo J. Kim\n",
        "\n",
        "[[paper](https://arxiv.org/abs/2210.07562)] [[github](https://github.com/mlvlab/TokenMixup)]\n",
        "\n",
        "This Tutorial : https://github.com/mlvlab/KCCV2023_TokenMixup_Tutorial\n",
        "\n",
        "![htm_gif](https://raw.githubusercontent.com/mlvlab/TokenMixup/main/assets/HTM.gif)\n",
        "\n",
        "\n",
        "#### 1. Sample Difficulty Assessment (ScoreNet)\n",
        "#### 2. Attention-guided Saliency Detection\n",
        "#### 3. Optimal Assignment\n",
        "#### 4. Token-level Mixup"
      ],
      "metadata": {
        "id": "FT1xYGJbcBol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-------------\n",
        "\n",
        "<br>\n",
        "\n",
        "## **실습 내용**\n",
        "\n",
        "#### [1] TokenMixup 코드 리뷰\n",
        "- 사전작업\n",
        "- TokenMixup 모듈 코드 읽어보기\n",
        "- 모델 로드 및 Input Mixup 알아보기\n",
        "\n",
        "#### [2] ScoreNet 알아보기\n",
        "- ScoreNet의 예측이 정확한가?\n",
        "- ScoreNet이 \"어려움\"의 척도(Proxy)가 될 수 있을까?\n",
        "\n",
        "#### [3] Saliency Map 알아보기\n",
        "- Attention 기반 방법이 정말 Salient한 영역을 잘 탐지하는가?\n",
        "- TokenMixup을 통해 Saliency가 어떻게 향상되는가?\n",
        "\n",
        "<br>\n",
        "\n",
        "-------------"
      ],
      "metadata": {
        "id": "XhJ4HE2zemXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[1] TokenMixup 코드 리뷰**\n",
        "\n",
        "### 사전 작업"
      ],
      "metadata": {
        "id": "FhI-AtAAgqqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38fdeCw4bekg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mlvlab/TokenMixup.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install timm==0.6.7"
      ],
      "metadata": {
        "id": "QOZP2D1WdDoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 파라미터 다운로드\n",
        "%cd TokenMixup/experiments/\n",
        "import gdown\n",
        "gdown.download_folder('https://drive.google.com/drive/u/0/folders/1_iSo8cA088yg_y0naQQX3Vc6Q7jCGsQk')"
      ],
      "metadata": {
        "id": "vV07wSd-eI1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TokenMixup 모듈 코드 읽어보기"
      ],
      "metadata": {
        "id": "t7bI7K0MeYFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "아래 코드는 설명을 위해 매우 간추린 버전으로, Compact Convolutional Transformer 모델과 같이 CLS 토큰이 없는 모델을 가정한 경우의 코드입니다. \n",
        "\n",
        "FULL CODE : [ [LINK](https://github.com/mlvlab/TokenMixup/blob/main/tokenmixup/horizontal.py) ]\n",
        "```\n",
        "class HorizontalTokenMixupLayer(nn.Module):\n",
        "    def __init__(self, layer, tau, rho, scorenet_lambda,\n",
        "                       ... ):\n",
        "        super().__init__()\n",
        "\n",
        "        # configs\n",
        "        self.tau = tau\n",
        "        self.rho = rho\n",
        "        self.scorenet_lambda = scorenet_lambda\n",
        "        self.aspect_ratio = aspect_ratio\n",
        "\n",
        "        ...\n",
        "\n",
        "        # encoder block\n",
        "        self.layer = layer\n",
        "        \n",
        "        # scorenet\n",
        "        self.scorenet_attn = nn.Linear(d_model, 1)\n",
        "        self.scorenet_fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x, y=None, *args, **kwargs):\n",
        "        \n",
        "        if not self.training :\n",
        "            return self.layer(x, y, *args, **kwargs)\n",
        "\n",
        "\n",
        "        # 1. Sample Difficulty Assessment\n",
        "        self.difficulty_score = torch.zeros(BATCHSIZE, dtype=float)\n",
        "        \n",
        "        a = F.softmax(self.scorenet_attn(x), dim=1).transpose(-1, -2)\n",
        "        scorenet_x = torch.matmul(a, x).squeeze(-2)\n",
        "        scorenet_pred = self.scorenet_fc(scorenet_x)\n",
        "        scorenet_loss = torch.sum(-y * F.log_softmax(scorenet_pred, dim=-1), dim=-1)\n",
        "\n",
        "        self.difficulty_score = scorenet_loss.data\n",
        "        apply_tokenmixup = self.difficulty_score <= self.tau\n",
        "\n",
        "\n",
        "        # 2. Attention-guided Saliency Detection\n",
        "        attn = self.layer.get_attention_map(x.data, y, *args, **kwargs).data\n",
        "        _, attn_heads, attn_qdim, attn_kdim = attn.shape\n",
        "\n",
        "        saliency = attn.mean(dim=[1, 2])\n",
        "        x_to_mix, x_no_mix = x[apply_tokenmixup], x[~apply_tokenmixup]\n",
        "        y_to_mix, y_no_mix = y[apply_tokenmixup], y[~apply_tokenmixup]\n",
        "        saliency_to_mix = saliency[apply_tokenmixup] \n",
        "\n",
        "\n",
        "        # 3. Optimal Assignment\n",
        "        raw_saliency_diff = saliency.repeat(mix_sample_num,1,1) - saliency_to_mix.reshape(mix_sample_num,1,N).repeat(1,B,1)\n",
        "        saliency_diff = torch.clamp(raw_saliency_diff - self.rho, 0.0)\n",
        "        saliency_diff_agg = saliency_diff.sum(dim=2)\n",
        "        saliency_index = torch.tensor(linear_sum_assignment(-saliency_diff_agg)[1])\n",
        "        saliency_pair_to_mix = saliency[saliency_index]\n",
        "\n",
        "        \n",
        "        # 4. Token-level Mixup\n",
        "        # actual mixup for x\n",
        "        M  = torch.gather(saliency_diff, 1, saliency_index.unsqueeze(dim=-1).repeat(1, 1, N)).squeeze() > 0\n",
        "        x_mixed = (~M).unsqueeze(-1).repeat(1, 1, D) * x_to_mix + M.unsqueeze(-1).repeat(1, 1, D) * x[saliency_index]\n",
        "        x_mixed = torch.cat([x_mixed, x_no_mix], dim=0)\n",
        "\n",
        "        # actual mixup for y\n",
        "        i = (saliency_to_mix * (~M)).sum(1)\n",
        "        j = (saliency_pair_to_mix * M).sum(1)\n",
        "        ratio_to_mix = (i / (i + j)).unsqueeze(-1)\n",
        "        ratio_pair_to_mix = (j / (i + j)).unsqueeze(-1)\n",
        "        y_mixed = ratio_to_mix * y_to_mix + ratio_pair_to_mix * y[saliency_index]\n",
        "        y_mixed = torch.cat([y_mixed, y_no_mix], dim=0)\n",
        "\n",
        "        return self.layer(x_mixed, y_mixed, *args, **kwargs)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DXHoyeMcz4Ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 로드 및 Input Mixup 알아보기"
      ],
      "metadata": {
        "id": "n90Ta-7Os_Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from timm.models import create_model\n",
        "from timm.data import create_dataset, create_loader, Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy"
      ],
      "metadata": {
        "id": "tmZy_0CTiKZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Model\n",
        "from cct.src.cct import cct_7_3x1_32\n",
        "\n",
        "model = cct_7_3x1_32(\n",
        "        horizontal_mixup = True,\n",
        "        horizontal_layer = 2,  # 세번째 Layer에서 (Horizontal) TokenMixup 적용\n",
        "        rho = 0.003,           # Saliency Difference Threshold\n",
        "        tau = 100,             # Sample Difficulty Threshold : 모두 섞기 위해 임의로 100 지정\n",
        "        scorenet_stopgrad = False,\n",
        "        scorenet_train = True,\n",
        "        vertical_mixup = False,\n",
        "        vertical_layer = -1,\n",
        "        kappa = 0,\n",
        "        vertical_stopgrad = True,\n",
        "        img_size = 32,\n",
        "        seq_pool = True,\n",
        "        pretrained = False,\n",
        "        num_classes = 10,\n",
        "        drop_rate = 0.0,\n",
        "        drop_connect_rate = 0.0,\n",
        "        drop_block_rate = 0.0,\n",
        "        global_pool = 0,\n",
        "        bn_tf = False,\n",
        "        bn_momentum = 0.0,\n",
        "        bn_eps = 0.0,\n",
        "        scriptable = False,\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(\"TokenMixup-KCCV/cct_cifar10_htm.pth.tar\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "\n",
        "loss_fn = SoftTargetCrossEntropy()"
      ],
      "metadata": {
        "id": "87yOM5MWmHQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "# Setup Dataset and Data Loader\n",
        "dataset_train = create_dataset(\n",
        "    \"torch/cifar10\", download=True, batch_size=BATCH_SIZE,\n",
        "    root=\"./\", split=\"train\", is_training=True\n",
        ")\n",
        "loader_train = create_loader(dataset_train, input_size=(3,32,32), \n",
        "                             batch_size=BATCH_SIZE, use_prefetcher=False,\n",
        "                             mean=[0.4914, 0.4822, 0.4465],\n",
        "                             std=[0.247, 0.2435, 0.2616])\n",
        "\n",
        "dataset_test = create_dataset(\n",
        "    \"torch/cifar10\", download=True, batch_size=BATCH_SIZE,\n",
        "    root=\"./\", split=\"test\", is_training=False\n",
        ")\n",
        "loader_test = create_loader(dataset_test, input_size=(3,32,32), \n",
        "                             batch_size=BATCH_SIZE, use_prefetcher=False,\n",
        "                             mean=[0.4914, 0.4822, 0.4465],\n",
        "                             std=[0.247, 0.2435, 0.2616])\n",
        "\n",
        "# Setup Input Mixup\n",
        "mixup_fn = Mixup(mixup_alpha=10, cutmix_alpha=0.0, cutmix_minmax=None,\n",
        "                 switch_prob=0.0, mode=\"batch\", label_smoothing=0.1, \n",
        "                 num_classes=10, prob=1.0)\n",
        "no_mixup = Mixup(mixup_alpha=10, cutmix_alpha=0.0, cutmix_minmax=None,\n",
        "                 switch_prob=0.0, mode=\"batch\", label_smoothing=0.1, \n",
        "                 num_classes=10, prob=0.0)"
      ],
      "metadata": {
        "id": "iLa5lO4Mq7wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "for bidx, (input, target) in enumerate(loader_train):\n",
        "  if bidx in [1] :\n",
        "    # Input Mixup X\n",
        "    raw_input, raw_target = no_mixup(input, target)\n",
        "    out = torchvision.utils.make_grid(raw_input)\n",
        "    out = torch.clamp(out * torch.tensor([[[0.247]],[[0.2435]],[[0.2616]]]) + torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]), 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.title([LABELS[x.argmax(0).item()] for x in raw_target])\n",
        "    plt.imshow(out.permute(1,2,0))\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    model.eval()    \n",
        "    raw_pred = model(raw_input, raw_target)\n",
        "    raw_losses = torch.sum(-raw_target * torch.nn.functional.log_softmax(raw_pred, dim=-1), dim=-1)\n",
        "    print(\"Sample Losses = {:.4f}, {:.4f}, {:.4f}, {:.4f}\\n\\n\".format(*raw_losses))\n",
        "\n",
        "    # Input Mixup O\n",
        "    mix_input, mix_target = mixup_fn(input, target)\n",
        "    out = torchvision.utils.make_grid(mix_input)\n",
        "    out = torch.clamp(out * torch.tensor([[[0.247]],[[0.2435]],[[0.2616]]]) + torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]), 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.title([LABELS[x.topk(2).indices[0]]+'+'+LABELS[x.topk(2).indices[1]] for x in mix_target])\n",
        "    plt.imshow(out.permute(1,2,0))\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    mix_pred = model(mix_input, mix_target)\n",
        "    mix_losses = torch.sum(-mix_target * torch.nn.functional.log_softmax(mix_pred, dim=-1), dim=-1)\n",
        "    print(\"Sample Losses = {:.4f}, {:.4f}, {:.4f}, {:.4f}\\n\\n\".format(*mix_losses))\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "ULcHws3Xw8Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[2] ScoreNet 알아보기**\n",
        "\n",
        "### ScoreNet의 예측이 정확한가?\n",
        "\n"
      ],
      "metadata": {
        "id": "s8kLCjlTszcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "for bidx, (input, target) in enumerate(loader_test):\n",
        "  if bidx in [2] :\n",
        "    raw_input, raw_target = no_mixup(input, target)\n",
        "    out = torchvision.utils.make_grid(raw_input)\n",
        "    out = torch.clamp(out * torch.tensor([[[0.247]],[[0.2435]],[[0.2616]]]) + torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]), 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.title([LABELS[x.argmax(0).item()] for x in raw_target])\n",
        "    plt.imshow(out.permute(1,2,0))\n",
        "    plt.pause(0.001)\n",
        "    \n",
        "    model.eval()\n",
        "    raw_pred = model(raw_input, raw_target)\n",
        "    model.train()\n",
        "    _, _, raw_scorenet_output, _, _, _ = model(raw_input, raw_target)\n",
        "    raw_losses = torch.sum(-raw_target * torch.nn.functional.log_softmax(raw_pred, dim=-1), dim=-1)\n",
        "    raw_sn_losses = torch.sum(-raw_target * torch.nn.functional.log_softmax(raw_scorenet_output, dim=-1), dim=-1)\n",
        "    print(\"Model    Predictions = {}, {}, {}, {}\".format(*[LABELS[x.argmax(0).item()] for x in raw_pred]))\n",
        "    print(\"ScoreNet Predictions = {}, {}, {}, {}\\n\\n\".format(*[LABELS[x.argmax(0).item()] for x in raw_scorenet_output]))\n",
        "\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "VzSIFvS3_4Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ScoreNet이 \"어려움\"의 척도가 될 수 있을까?"
      ],
      "metadata": {
        "id": "x04owyhJ_1Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "MODEL_LOSSES = []\n",
        "SCORENET_LOSSES = []\n",
        "\n",
        "for bidx, (input, target) in tqdm.tqdm(enumerate(loader_test)):\n",
        "\n",
        "  mix_input, mix_target = mixup_fn(input, target)\n",
        "  model.eval()\n",
        "  mix_pred = model(mix_input, mix_target)\n",
        "  model.train()\n",
        "  mix_scorenet_output = model(mix_input, mix_target)[2]\n",
        "\n",
        "  mix_losses = torch.sum(-mix_target * torch.nn.functional.log_softmax(mix_pred, dim=-1), dim=-1)\n",
        "  mix_sn_losses = torch.sum(-mix_target * torch.nn.functional.log_softmax(mix_scorenet_output, dim=-1), dim=-1)\n",
        "  \n",
        "  MODEL_LOSSES += list(np.array(mix_losses.detach()))\n",
        "  SCORENET_LOSSES += list(np.array(mix_sn_losses.detach()))\n",
        "\n",
        "  if bidx == 19 : break"
      ],
      "metadata": {
        "id": "_aFgWXX4szQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot\n",
        "fig, ax = plt.subplots(figsize = (5, 5))\n",
        "ax.scatter(SCORENET_LOSSES, MODEL_LOSSES, s=60, alpha=0.7, edgecolors=\"k\")\n",
        "plt.xlim(min(SCORENET_LOSSES)-0.3,max(SCORENET_LOSSES)+0.3)\n",
        "plt.ylim(min(MODEL_LOSSES)-0.3,max(MODEL_LOSSES)+0.3)\n",
        "plt.xlabel('Scorenet Loss')\n",
        "plt.ylabel('Model Loss')\n",
        "plt.title(\"PEARSON CORR. : {:.2f}\".format(np.corrcoef(SCORENET_LOSSES, MODEL_LOSSES)[0,1]))\n",
        "\n",
        "# Line Plot\n",
        "b, a = np.polyfit(SCORENET_LOSSES, MODEL_LOSSES, deg=1)\n",
        "xseq = np.linspace(min(SCORENET_LOSSES)-0.2, max(SCORENET_LOSSES)+0.2, num=100)\n",
        "ax.plot(xseq, a + b * xseq, color=\"r\", lw=2.5);\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Hx-WPbh91VKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "# **[3] Saliency Map 알아보기**\n",
        "\n",
        "### Attention 기반 방법이 정말 Salient한 영역을 잘 탐지하는가?"
      ],
      "metadata": {
        "id": "kDlWourVI2Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TokenMixup 을 수행하지 않는 모델을 따로 정의\n",
        "\n",
        "from cct.src.cct import cct_7_3x1_32\n",
        "\n",
        "raw_model = cct_7_3x1_32(\n",
        "        horizontal_mixup = False,\n",
        "        horizontal_layer = -1,\n",
        "        rho = 0.00,          \n",
        "        tau = 0.0,            \n",
        "        scorenet_stopgrad = False,\n",
        "        scorenet_train = True,\n",
        "        vertical_mixup = False,\n",
        "        vertical_layer = -1,\n",
        "        kappa = 0,\n",
        "        vertical_stopgrad = True,\n",
        "        img_size = 32,\n",
        "        seq_pool = True,\n",
        "        pretrained = False,\n",
        "        num_classes = 10,\n",
        "        drop_rate = 0.0,\n",
        "        drop_connect_rate = 0.0,\n",
        "        drop_block_rate = 0.0,\n",
        "        global_pool = 0,\n",
        "        bn_tf = False,\n",
        "        bn_momentum = 0.0,\n",
        "        bn_eps = 0.0,\n",
        "        scriptable = False,\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(\"TokenMixup-KCCV/cct_cifar10_htm.pth.tar\", map_location=torch.device('cpu'))\n",
        "raw_model.load_state_dict(checkpoint['state_dict'], strict=False)"
      ],
      "metadata": {
        "id": "mXoPLCX7g7Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "TOPK = 50\n",
        "\n",
        "for bidx, (input, target) in enumerate(loader_train):\n",
        "  if bidx in [10,14] :\n",
        "    raw_input, raw_target = no_mixup(input, target)\n",
        "    out = torchvision.utils.make_grid(raw_input)\n",
        "    out = torch.clamp(out * torch.tensor([[[0.247]],[[0.2435]],[[0.2616]]]) + torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]), 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.title([LABELS[x.argmax(0).item()] for x in raw_target])\n",
        "    plt.imshow(out.permute(1,2,0))\n",
        "    plt.pause(0.001)\n",
        "\n",
        "    # Get Saliency with Attention\n",
        "    model.train()    \n",
        "    raw_pred, raw_lbl, raw_scorenet_output, raw_attns, raw_K1s, raw_K2s = raw_model(raw_input, raw_target)\n",
        "    \n",
        "    for i, at in enumerate(raw_attns[2:]):\n",
        "      if i == 0 :\n",
        "        sal = at\n",
        "      else :\n",
        "        sal = torch.matmul(sal.transpose(3,2), at)\n",
        "    saliency = sal.mean(dim=[1, 2])\n",
        "\n",
        "    # Select Top Salient Tokens\n",
        "    topk = torch.topk(saliency, 256 - TOPK, largest=False)\n",
        "    top_sal = saliency.scatter_(1, topk.indices, 0).reshape(BATCH_SIZE, 16,16)\n",
        "    saliency = torch.nn.functional.interpolate(top_sal.unsqueeze(1), size=(32,32))\n",
        "    sal_map = torch.nn.functional.pad(saliency,(0,0,0,0,1,1))\n",
        "    \n",
        "    out = torchvision.utils.make_grid(raw_input + 255 * sal_map)\n",
        "    out = torch.clamp(out * torch.tensor([[[0.247]],[[0.2435]],[[0.2616]]]) + torch.tensor([[[0.4914]],[[0.4822]],[[0.4465]]]), 0, 1)\n",
        "    \n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.title([LABELS[x.argmax(0).item()] for x in raw_target])\n",
        "    plt.imshow(out.permute(1,2,0))\n",
        "    plt.pause(0.001)\n",
        "\n",
        "  elif bidx > 14 :\n",
        "    break"
      ],
      "metadata": {
        "id": "rtkCa9Kk1VT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### TokenMixup을 통해 Saliency가 어떻게 향상되는가?"
      ],
      "metadata": {
        "id": "-6Xs2o_Ehims"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "RHOS = [0.000, 0.001, 0.003, 0.005, 0.007, 0.01, 1.0]\n",
        "\n",
        "SAL_INC = [[],[],[],[],[],[],[]]\n",
        "\n",
        "for bidx, (input, target) in tqdm.tqdm(enumerate(loader_train)):\n",
        "  raw_input, raw_target = no_mixup(input, target)\n",
        "\n",
        "  # Saliency without TokenMixup\n",
        "  raw_model.train()    \n",
        "  raw_pred, raw_lbl, raw_scorenet_output, raw_attns, raw_K1s, raw_K2s = raw_model(raw_input, raw_target)\n",
        "  for i, at in enumerate(raw_attns[2:]):\n",
        "    if i == 0 :\n",
        "      raw_sal = at\n",
        "    else :\n",
        "      raw_sal = torch.matmul(raw_sal.transpose(3,2), at)\n",
        "  raw_sal = raw_sal.mean(dim=[1, 2])\n",
        "\n",
        "  raw_saliency_diff = raw_sal.repeat(4,1,1) - raw_sal.reshape(4,1,256).repeat(1,4,1)\n",
        "  for i, rho in enumerate(RHOS) :\n",
        "    saliency_diff = torch.clamp(raw_saliency_diff - rho, 0.0)\n",
        "    SAL_INC[i] += list(np.array(saliency_diff.mean(1).sum(1)))\n",
        "\n",
        "  if bidx == 14 :\n",
        "    break\n",
        "  \n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "pos = np.arange(len(SAL_INC)) + 1\n",
        "bp = ax.boxplot(SAL_INC, positions=pos, sym='k+', patch_artist=True, boxprops=dict(facecolor='lightblue', color='k'))\n",
        "plt.xticks(pos, RHOS)\n",
        "plt.xlabel(\"Saliency Difference Threshold (Rho)\")\n",
        "plt.ylabel(\"Saliency Increase\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "y1xKJSrchvFw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}